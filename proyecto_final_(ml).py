# -*- coding: utf-8 -*-
"""Proyecto Final (ML).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CaF6HefrWefWAJbUQp8w4VxA6_zCMDlS

#Proyecto Final

### Iran Ocampo Arteaga

#Regresión

###Esperanza de vida, obtenida por la OMS

 Los datos contienen 2938 filas y 22 columnas.

 Las columnas incluyen:
*   país
*   año
*   estado de desarrollo
*   mortalidad de dultos
*   esperanza de vida
*   muertes infantiles
*   consumo de alcohol per cápita
*   gastos del país en salud
*   cobertura de inmunización
*   IMC
*   muertes menores de 5 años
*   muertes por VIH/SIDA
*   PIB
*   población
*   condición corporal
*  información sobre ingresos
*   educación.
"""

import pandas as pd
import numpy as np

column_names_1 = [
    "País",
    "Año",
    "Estado",
    "Esperanza_de_vida",
    "Mortalidad_Adulta",
    "Muertes_infantiles",
    "Alcohol",
    "Porcentaje_de_gastos",
    "Hepatitis_B",
    "Sarampión",
    "IMC",
    "Muertes_menores_de_5",
    "Polio",
    "Gastos_totales",
    "Difteria",
    "VIH/Sida",
    "GDP",
    "Población",
    "delgadez 1-19 años",
    "delgadez 5-9 años",
    "Composición_de_la_renta_de_los_recursos",
    "Escolaridad"
]

df = pd.read_csv("./Esperanza_de_vida.csv", header=None, names=column_names_1)
print(df.head())

print(df.dtypes)

columnas_con_0 = [ "Año", "Esperanza_de_vida", "Mortalidad_Adulta", "Muertes_infantiles", "Alcohol",
    "Porcentaje_de_gastos", "Hepatitis_B", "Sarampión", "IMC", "Muertes_menores_de_5", "Polio",
    "Gastos_totales", "Difteria", "VIH/Sida", "GDP", "Población",
    "delgadez 1-19 años", "delgadez 5-9 años", "Composición_de_la_renta_de_los_recursos", "Escolaridad"]
df[columnas_con_0] = df[columnas_con_0].replace(0, np.nan)
df

df.info()

import matplotlib.pyplot as plt

df.hist(figsize=(10, 10))
plt.tight_layout()
plt.show()

columnas_eliminadas=['País', 'Estado']
df.drop(columnas_eliminadas, axis=1)

"""###Preprocesamiento"""

from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer
#imputar
imputer = SimpleImputer(strategy="mean")
df_imputed = pd.DataFrame(imputer.fit_transform(df.drop(columnas_eliminadas, axis=1)), columns= columnas_con_0)
df_imputed

df_imputed.info()

#Revisar la correlación de los datos, con el valor de pi
import statsmodels.api as sm
results = sm.OLS(df_imputed['Esperanza_de_vida'], df_imputed[["Año", "Mortalidad_Adulta", "Muertes_infantiles", "Alcohol",
    "Porcentaje_de_gastos", "Hepatitis_B", "Sarampión", "IMC", "Muertes_menores_de_5", "Polio",
    "Gastos_totales", "Difteria", "VIH/Sida", "GDP", "Población",
    "delgadez 1-19 años", "delgadez 5-9 años", "Composición_de_la_renta_de_los_recursos", "Escolaridad"]]).fit()
print(results.summary())

# Eliminamos las columnas innecesarias por el valor de P>|t|
columnas_innecesarias=['Alcohol','Población', 'GDP', 'delgadez 1-19 años', 'delgadez 5-9 años', 'Porcentaje_de_gastos']
df_new= df_imputed.drop(columnas_innecesarias, axis=1)
df_new

"""## Regresion lineal"""

#Normalizacion
scaler = StandardScaler()
df_normalized = pd.DataFrame(scaler.fit_transform(df_new))
df_normalized

data_reg = df_normalized.copy()
data_reg = data_reg.values

y = data_reg[:, 2]
X = np.delete(data_reg, 2, axis=1)
m = y.size
y = y.reshape((m, 1))

def computeCostMulti(X, y, theta):
    m = y.shape[0]
    J = 0.0
    J = 1./(2. * m) * np.sum((np.dot(X, theta) - y)**2)
    return J

def gradientDescentMulti(X, y, theta, alpha, num_iters):

    m = y.shape[0]

    theta = theta.copy()

    J_history = []

    for i in range(num_iters):
        theta = theta - (alpha/m) * np.dot(X.T, (np.dot(X, theta) - y))
        J_history.append(computeCostMulti(X, y, theta))

    return theta, J_history

alpha = 0.01
num_iters = 1000

theta = np.zeros((X.shape[1], 1))
theta, J_history = gradientDescentMulti(X, y, theta, alpha, num_iters)

plt.plot(np.arange(len(J_history)), J_history, lw=2)
plt.xlabel('Number of iterations')
plt.ylabel('Cost J')

print('theta computed from gradient descent: {:s}'.format(str(theta)))

"""##Regularizacion"""

import seaborn as sns
import matplotlib.pyplot as plt

sns.pairplot(df_new, x_vars=["Año", "Mortalidad_Adulta", "Muertes_infantiles",
                                 "Hepatitis_B", "Sarampión", "IMC", "Muertes_menores_de_5", "Polio",
                                 "Gastos_totales", "Difteria", "VIH/Sida", "Composición_de_la_renta_de_los_recursos", "Escolaridad"], y_vars='Esperanza_de_vida', height=5, aspect=1, kind='reg')
plt.show()

#Normalizar
scaler = StandardScaler()
X = scaler.fit_transform(df_new[["Año", "Mortalidad_Adulta", "Muertes_infantiles",
                                     "Hepatitis_B", "Sarampión", "IMC", "Muertes_menores_de_5", "Polio",
                                     "Gastos_totales", "Difteria", "VIH/Sida", "Composición_de_la_renta_de_los_recursos", "Escolaridad"]])
y = df_new['Esperanza_de_vida']

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X,y, train_size=0.80, random_state=6000)

print(f"Entrenamiento: {X_train.shape,y_train.shape}")
print(f"Prueba: {X_test.shape,y_test.shape}")

from sklearn.linear_model import Ridge

lr = Ridge(alpha=2)
lr.fit(X_train,y_train)

print(f"Entrenamiento: {lr.score(X_train,y_train)}")
print(f"Prueba: {lr.score(X_test,y_test)}")

from sklearn.metrics import mean_absolute_error, mean_squared_error

prediction_train = lr.predict(X_train)
print('R^2 value: ',lr.score(X_train,y_train))
print('Mean squared error: ',mean_squared_error(y_train,prediction_train))
print('Mean absolute error: ',mean_absolute_error(y_train,prediction_train))

prediction_test = lr.predict(X_test)
print('R^2 value: ',lr.score(X_test,y_test))
print('Mean squared error: ',mean_squared_error(y_test,prediction_test))
print('Mean absolute error: ',mean_absolute_error(y_test,prediction_test))

"""##Random Forest"""

from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler


X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.80, random_state=6000)

rf_regressor = RandomForestRegressor(random_state=6000)
rf_regressor.fit(X_train, y_train)

y_pred = rf_regressor.predict(X_test)

mse = mean_squared_error(y_test, y_pred)
mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"Mean Squared Error (MSE): {mse:.2f}")
print(f"Mean Absolute Error (MAE): {mae:.2f}")
print(f"R^2 Value: {r2:.2f}")

"""##Conclusiones (modelos lineales)"""

data = {
    "Modelo": ["Regularización", "Random Forest"],
    "R^2 value": [0.8228898139836642, 0.96],
    "Mean squared error": [16.511541878814434, 4.12],
    "Mean absolute error": [2.8391243294391906, 1.25]
}

df = pd.DataFrame(data)
df

"""Considerando los resultados observados, optaría por utilizar el modelo de Random Forest. Este modelo demuestra un mejor rendimiento en el aprendizaje y ofrece resultados superiores en comparación con la regularización. Los valores de evaluación del modelo de Random Forest son significativamente mejores, con un menor error cuadrático medio (MSE) y un menor error absoluto medio (MAE), así como un valor de R^2más alto, lo que indica una mejor capacidad de predicción y ajuste a los datos.

#Clasificación

Es un dataset sobre la predicción de muerte por una falla en el corazón



Los datos contienen 13 columnas y 5000 filas (pacientes)

Las columnas incluyen:
* edad: edad del paciente (años)
* anemia: disminución de glóbulos rojos o hemoglobina (booleano)
* creatinina fosfoquinasa (CPK): nivel de la enzima CPK en la sangre (mcg/L)
* diabetes: si el paciente tiene diabetes (booleano)
* fracción de eyección: porcentaje de sangre que sale del corazón en cada contracción (porcentaje)
* hipertensión arterial: si el paciente tiene hipertensión (booleano)
* plaquetas: plaquetas en la sangre (kiloplaquetas/mL)
* sexo: mujer u hombre (binario)
* creatinina sérica: nivel de creatinina sérica en la sangre (mg/dL)
* sodio sérico: nivel de sodio sérico en sangre (mEq/L)
* tabaquismo: si el paciente fuma o no (booleano)
* tiempo: periodo de seguimiento (días)
* Muerte: si el paciente falleció durante el periodo de seguimiento (booleano)
"""

nombres=[
    'edad',
    'anemia',
    'creatinina_fosfoquinasa',
    'diabetes',
    'fraccion_eyección',
    'hipertensión_arterial',
    'plaquetas',
    'creatinina_sérica',
    'sodio_sérico',
    'sexo',
    'tabaquismo',
    'tiempo',
    'Muerte'
]
ds = pd.read_csv("./corazon.csv", header= None, names=nombres)
ds

print(ds.dtypes)

ds.info()

import matplotlib.pyplot as plt

ds.hist(figsize=(10, 10))
plt.tight_layout()
plt.show()

"""##Regresion logistica"""

from sklearn.model_selection import train_test_split

X = ds.drop('Muerte', axis=1)
y = ds['Muerte']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)

from sklearn.pipeline import Pipeline
from sklearn.feature_selection import SelectKBest, VarianceThreshold
from sklearn.preprocessing import MinMaxScaler
from sklearn.linear_model import LogisticRegression

selector = VarianceThreshold(0.25)
scaler = MinMaxScaler()
clf = LogisticRegression()

pl = Pipeline([('selector',selector), ('escalador',scaler), ('clasificador',clf)])

pl.fit(X_train,y_train)

from sklearn.model_selection import StratifiedKFold, cross_val_score

skf = StratifiedKFold(n_splits=5)

cvs = cross_val_score(pl, X_train, y_train, cv=skf)

print(f"Precisión en el conjunto de entrenamiento: {pl.score(X_train, y_train)}")
print(f"Precisión en el conjunto de prueba: {pl.score(X_test, y_test)}")

from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score
from sklearn.metrics import classification_report, confusion_matrix

y_pred = pl.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)

print("El accuracy es de:", accuracy)
print("El f1_score es de:", f1)
print("La precision es de:", precision)
print("El recall es de:", recall)
print()
print(confusion_matrix(y_test, y_pred))

import matplotlib.pyplot as plt
import seaborn as sns

conf_matrix = confusion_matrix(y_test, y_pred)


plt.figure(figsize=(6, 4))

sns.heatmap(conf_matrix, annot=True, cmap='Blues', fmt='g', cbar=False,
            xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])

plt.xlabel('Prediccion')
plt.ylabel('Valor real')
plt.title('Matriz de confusion')

plt.show()

from sklearn.model_selection import GridSearchCV

param_grid = {
    'selector__threshold': [0.1, 0.2, 0.25, 0.3],
    'clasificador__C': [0.01, 0.1, 1, 10, 100],
    'clasificador__penalty': ['l1', 'l2'],
    'clasificador__solver': ['liblinear', 'saga']
}

grid_search = GridSearchCV(pl, param_grid, cv=5, scoring='accuracy')

grid_search.fit(X_train, y_train)

# Resultados
print("Mejores parámetros encontrados:", grid_search.best_params_)
print("Mejor precisión de CV:", grid_search.best_score_)

# Evaluar en el conjunto de prueba
best_model = grid_search.best_estimator_
print("Precisión en el conjunto de prueba:", best_model.score(X_test, y_test))

predictions = best_model.predict(X_test)
f1 = f1_score(y_test, predictions)
precision = precision_score(y_test, predictions)
recall = recall_score(y_test, predictions)


print("El f1_score es de:", f1)
print("La precision es de:", precision)
print("El recall es de:", recall)

conf_matrix = confusion_matrix(y_test, predictions)


plt.figure(figsize=(6, 4))

sns.heatmap(conf_matrix, annot=True, cmap='Blues', fmt='g', cbar=False,
            xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])

plt.xlabel('Prediccion')
plt.ylabel('Valor real')
plt.title('Matriz de confusion')

plt.show()

"""**Antes de gridsearch:**

El accuracy es de: 0.85

El f1_score es de: 0.7440273037542662

La precision es de: 0.7860576923076923

El recall es de: 0.7062634989200864

**GridSearch:**

Precisión en el conjunto de prueba: 0.8606666666666667

El f1_score es de: 0.7633069082672707

La precision es de: 0.8023809523809524

El recall es de: 0.7278617710583153

##Balancear
"""

from imblearn.over_sampling import SMOTE
from collections import Counter
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split

X, y = make_classification(n_samples=1000, n_features=20, n_classes=2,
                           n_clusters_per_class=1, weights=[0.9, 0.1],
                           flip_y=0, random_state=1)

print('Distribución de clases antes de SMOTE:', Counter(y))

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Aplicar SMOTE
smote = SMOTE(random_state=42)
X_res, y_res = smote.fit_resample(X_train, y_train)

print('Distribución de clases después de SMOTE:', Counter(y_res))

model = LogisticRegression(random_state=42, max_iter=10000)
model.fit(X_res, y_res)

y_pred = model.predict(X_test)

print()

accuracy = accuracy_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)

print("El accuracy es de:", accuracy)
print("El f1_score es de:", f1)
print("La precision es de:", precision)
print("El recall es de:", recall)

conf_matrix = confusion_matrix(y_test, y_pred)

plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, cmap='Blues', fmt='g', cbar=False,
            xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])

plt.xlabel('Prediccion')
plt.ylabel('Valor real')
plt.title('Matriz de confusion')
plt.show()

"""##Random Forest"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier


X = ds.drop('Muerte', axis=1)
y = ds['Muerte']

#separo los datos
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

#creo el modelo
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)


y_pred = rf_model.predict(X_test)


accuracy = accuracy_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
print("La acurracy es:" , accuracy)
print("El f1_score es de:", f1)
print("La precision es de:", precision)
print("El recall es de:", recall)

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix

conf_matrix = confusion_matrix(y_test, y_pred)


plt.figure(figsize=(6, 4))

sns.heatmap(conf_matrix, annot=True, cmap='Blues', fmt='g', cbar=False,
            xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])

plt.xlabel('Prediccion')
plt.ylabel('Valor real')
plt.title('Matriz de confusion')

plt.show()

"""##Conclusiones (clasificación)"""

data = {
    "Modelo": [
        "Regresión Logística Sin Balance",
        "Regresión Logística GridSearch",
        "Regresión Logística Con Balance",
        "Random Forest"
    ],
    "Accuracy": [
        0.85,
        0.8606666666666667,
        0.9633333333333334,
        0.9913333333333333
    ],
    "F1 Score": [
        0.7440273037542662,
        0.7633069082672707,
        0.7924528301886793,
        0.9858233369683751
    ],
    "Precision": [
        0.7860576923076923,
        0.8023809523809524,
        0.84,
        0.9890590809628009
    ],
    "Recall": [
        0.7062634989200864,
        0.7278617710583153,
        0.75,
        0.9826086956521739
    ]
}

df = pd.DataFrame(data)
df

"""El modelo de regresión logística ofrece buenos resultados, pero son mejorables incluso después de aplicar grid search. Tras balancear los datos, el accuracy aumentó significativamente, aunque las demás métricas no mejoraron de manera proporcional. A pesar de ser un buen modelo, Random Forest demuestra un mejor rendimiento general, con métricas de evaluación superiores en todos los aspectos, lo que indica un aprendizaje más efectivo y una mejor capacidad predictiva."""